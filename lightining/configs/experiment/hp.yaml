# @package _global_

# to execute this experiment run:
# python train.py experiment=cifar10

defaults:
  - override /data: hp.yaml
  - override /model: gpt.yaml
  - override /trainer: default.yaml
  - override /logger: many_loggers.yaml
  - override /callbacks: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

experiment_name: "harry-potter-hparam-search-check"

callbacks:
  model_checkpoint:
    filename: "hp_{epoch:03d}"
    monitor: "val/loss"
    mode: "min"

  early_stopping:
    monitor: "val/loss"
    mode: "min"

tags:
  cifar10: "hparam_search_exp"

seed: 12345

trainer:
  min_epochs: 0
  max_epochs: 2

data:
  num_workers: 8

compile: False

logger:
  mlflow:
    tags: ${tags}
    experiment_name: ${experiment_name}